# glaid - Financial News & Portfolio Dashboard

<div align="center">
  <img src="DesignGuidelines/Logo.png" alt="glaid logo" width="120">
  <h3>Your Premium Financial News Aggregator</h3>
  <p>Track your portfolio and stay updated with the latest market developments for GOOG, EQIX, U, TDOC, & BTC.</p>
</div>

---

## âœ¨ Features

- ğŸ¨ **Premium Design** - Beautiful glassmorphism UI with glaid branding
- ğŸ’¹ **Portfolio Focused** - Strictly monitors news for: **Google (GOOG), Equinix (EQIX), Unity (U), Teladoc (TDOC), and Bitcoin (BTC)**
- â­ **Save Articles** - Bookmark your favorite articles with localStorage persistence
- ğŸ” **Smart Ticker Filtering** - Dedicated tabs to drill down into specific assets in your portfolio
- ğŸ·ï¸ **Automatic Tagging** - AI-driven tagging system that identifies tickers within general financial news
- ğŸ“± **Responsive** - Works beautifully on desktop, tablet, and mobile
- ğŸš€ **Fast & Lightweight** - Vanilla JavaScript, no frameworks needed

## ğŸ—ï¸ Architecture

The project follows the **A.N.T. 3-Layer Architecture**:

### Layer 1: Architecture (SOPs)
- `architecture/scraper_sop.md` - Web scraping guidelines
- `architecture/data_pipeline_sop.md` - Data flow specifications
- `architecture/dashboard_sop.md` - UI/UX specifications

### Layer 2: Tools (Executables)
- `tools/scrape_portfolio.py` - targeted Portfolio news scraper (Google & Yahoo News)
- `tools/scrape_yahoo_finance.py` - Yahoo Finance RSS scraper
- `tools/scrape_google_finance.py` - Google Finance RSS scraper
- `tools/filter_24h_articles.py` - Date-based article filter & ticker tagging
- `tools/deduplicate_articles.py` - Deduplication & payload generator

### Layer 3: Touchpoints (UI)
- `index.html` - Main portfolio dashboard
- `styles.css` - Design system & ticker-specific styling
- `app.js` - Application logic & filtering

## ğŸš€ Quick Start

### Prerequisites
- Python 3.7+
- Modern web browser

### Installation

1. **Install Python dependencies:**
```bash
pip3 install -r requirements.txt
```

2. **Run the data pipeline:**
```bash
./update_dashboard.sh
```

3. **Open the dashboard:**
```bash
open index.html
```

## ğŸ“– Usage

### Updating the Dashboard

Run the update script to fetch the latest articles:

```bash
./update_dashboard.sh
```

This will:
1. Scrape targeted news for your portfolio (GOOG, EQIX, U, TDOC, BTC)
2. Scrape general market news from Yahoo & Google Finance
3. Filter articles from the last 7 days matched against your portfolio
4. Automatically tag articles with ticker symbols
5. Generate the dashboard payload

### Dashboard Features

- **Filter by Asset**: Click tabs (Google, Bitcoin, etc.) to see news for specific holdings
- **Save Articles**: Click the â­ icon to save articles (persists in localStorage)
- **View Saved**: Click "Saved" tab to see your bookmarked articles
- **Refresh**: Click the refresh button to reload the data
- **Read Article**: Click anywhere on a card to open the article in a new tab

## ğŸ“ Project Structure

```
Trial/
â”œâ”€â”€ index.html                 # Main dashboard page
â”œâ”€â”€ styles.css                 # Design system & styling
â”œâ”€â”€ app.js                     # Application logic
â”œâ”€â”€ update_dashboard.sh        # Master update script
â”œâ”€â”€ requirements.txt           # Python dependencies
â”‚
â”œâ”€â”€ architecture/              # Layer 1: SOPs
â”‚   â”œâ”€â”€ scraper_sop.md
â”‚   â”œâ”€â”€ data_pipeline_sop.md
â”‚   â””â”€â”€ dashboard_sop.md
â”‚
â”œâ”€â”€ tools/                     # Layer 2: Executables
â”‚   â”œâ”€â”€ scrape_portfolio.py    # Targeted portfolio news
â”‚   â”œâ”€â”€ scrape_yahoo_finance.py
â”‚   â”œâ”€â”€ scrape_google_finance.py
â”‚   â”œâ”€â”€ filter_24h_articles.py
â”‚   â””â”€â”€ deduplicate_articles.py
â”‚
â”œâ”€â”€ .tmp/                      # Data files (auto-generated)
â”‚   â”œâ”€â”€ raw_portfolio.json
â”‚   â”œâ”€â”€ dashboard_payload.js   # Main data payload
â”‚
â”œâ”€â”€ DesignGuidelines/          # Brand assets
â”‚   â”œâ”€â”€ Logo.png
â”‚   â””â”€â”€ BrandDesign
```

## ğŸ› ï¸ Development

### Tech Stack
- **Backend**: Python 3, feedparser, requests
- **Frontend**: Vanilla HTML/CSS/JavaScript
- **Data Format**: JSON/JS (bypasses CORS for local execution)
- **Persistence**: localStorage

## ğŸš§ Roadmap

- [ ] Implement Supabase backend
- [ ] Add real-time stock price integration
- [ ] Add daily automated scraping (cron job)
- [ ] Add search functionality
- [ ] Add dark/light mode toggle

## ğŸ“ License

Â© 2026 glaid. All rights reserved.

---

<div align="center">
  <p>Built with â¤ï¸ using the A.N.T. Architecture</p>
  <p><strong>Powered by AI</strong></p>
</div>
